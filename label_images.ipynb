{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1fe39d",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "084eb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops, regionprops_table\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from importlib import reload\n",
    "import segmenteverygrain as seg\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from tqdm import trange\n",
    "import urllib.request\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7c981",
   "metadata": {},
   "source": [
    "### Enhance training images with Adaptive Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22c2eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "def perform_adaptive_equalization(img_path, clip_lim=0.01):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=clip_lim)\n",
    "\n",
    "    return(img_adapteq)\n",
    "\n",
    "image_dir = 'images/ara-train/'\n",
    "output_dir = image_dir + 'enhanced/'\n",
    "images = glob(image_dir + \"*.JPG\")\n",
    "\n",
    "for image in images:\n",
    "    output = perform_adaptive_equalization(image)\n",
    "    img_name = image.split(\"\\\\\")[1].split(\".\")[0] + '_enhanced' + '.jpg'\n",
    "    cv2.imwrite(output_dir + img_name, 255*output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ad8e0",
   "metadata": {},
   "source": [
    "### Download model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d253cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sam_vit_h_4b8939.pth', <http.client.HTTPMessage at 0x1dc916b1450>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth', 'sam_vit_h_4b8939.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7e32c",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f96ebad-c16a-46b2-a68c-ef1a1578a961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "model = seg.Unet()\n",
    "model.compile(optimizer=Adam(), loss=seg.weighted_crossentropy, metrics=[\"accuracy\"])\n",
    "model.load_weights('./checkpoints/seg_model_enhanced');\n",
    "\n",
    "sam = sam_model_registry[\"default\"](checkpoint=\"sam_vit_h_4b8939.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "391b47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sam.to(device='gpu')\n",
    "else:\n",
    "    sam.to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a57565d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bebab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525fa7a",
   "metadata": {},
   "source": [
    "### Run segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a306bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.23it/s]\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.29it/s]\n",
      "  0%|          | 0/312 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mask' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jeffr\\projects\\stranger-sections\\label_images.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeffr/projects/stranger-sections/label_images.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m big_im_pred \u001b[39m=\u001b[39m seg\u001b[39m.\u001b[39mpredict_big_image(big_im, model, I\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jeffr/projects/stranger-sections/label_images.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m labels, grains, coords \u001b[39m=\u001b[39m seg\u001b[39m.\u001b[39mlabel_grains(big_im, big_im_pred, dbs_max_dist\u001b[39m=\u001b[39m\u001b[39m10.0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jeffr/projects/stranger-sections/label_images.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m all_grains, labels, mask_all, grain_data, fig, ax \u001b[39m=\u001b[39m seg\u001b[39m.\u001b[39;49msam_segmentation(sam, big_im, big_im_pred, coords, labels, min_area\u001b[39m=\u001b[39;49m\u001b[39m50.0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jeffr\\projects\\stranger-sections\\.conda\\lib\\site-packages\\segmenteverygrain\\segmenteverygrain.py:419\u001b[0m, in \u001b[0;36msam_segmentation\u001b[1;34m(sam, big_im, big_im_pred, coords, labels, min_area)\u001b[0m\n\u001b[0;32m    417\u001b[0m y \u001b[39m=\u001b[39m coords[i,\u001b[39m1\u001b[39m]\n\u001b[0;32m    418\u001b[0m \u001b[39m# sx, sy, mask = one_point_prompt(x, y, ax, big_im, predictor)\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m labels_per_mask \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(labels[mask]))\n\u001b[0;32m    420\u001b[0m \u001b[39mif\u001b[39;00m (labels_per_mask \u001b[39m<\u001b[39m \u001b[39m10\u001b[39m) \u001b[39mand\u001b[39;00m (np\u001b[39m.\u001b[39mmean(big_im_pred[:,:,\u001b[39m0\u001b[39m][mask]) \u001b[39m<\u001b[39m \u001b[39m0.7\u001b[39m): \u001b[39m# skip masks that are mostly background\u001b[39;00m\n\u001b[0;32m    421\u001b[0m     poly \u001b[39m=\u001b[39m Polygon(np\u001b[39m.\u001b[39mvstack((sx, sy))\u001b[39m.\u001b[39mT)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'mask' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# reload(seg)\n",
    "\n",
    "fname = 'images/ara-train/enhanced/0c3n69_enhanced.jpg'\n",
    "# fname = 'adapteq_0smyr1.jpg'\n",
    "\n",
    "big_im = np.array(load_img(fname))\n",
    "big_im_pred = seg.predict_big_image(big_im, model, I=256)\n",
    "\n",
    "labels, grains, coords = seg.label_grains(big_im, big_im_pred, dbs_max_dist=10.0)\n",
    "all_grains, labels, mask_all, grain_data, fig, ax = seg.sam_segmentation(sam, big_im, big_im_pred, coords, labels, min_area=50.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d4581",
   "metadata": {},
   "source": [
    "### QC distribution of SAM prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "647ec413",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(big_im_pred)\n",
    "plt.scatter(coords[:,0], coords[:,1], c='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1dd22",
   "metadata": {},
   "source": [
    "### Delete or merge grains in segmentation result\n",
    "* click on the grain to remove and press 'x' key\n",
    "* click on two grains to merge, and press the 'm'm key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "bf00b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grain_inds = []\n",
    "cid1 = fig.canvas.mpl_connect('button_press_event', \n",
    "                              lambda event: seg.onclick2(event, all_grains, grain_inds, ax=ax))\n",
    "cid2 = fig.canvas.mpl_connect('key_press_event', \n",
    "                              lambda event: seg.onpress2(event, all_grains, grain_inds, fig=fig, ax=ax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78b47f",
   "metadata": {},
   "source": [
    "Run below cell once finished with editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9f84fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.canvas.mpl_disconnect(cid1)\n",
    "fig.canvas.mpl_disconnect(cid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f274343",
   "metadata": {},
   "source": [
    "Update the 'all_grains' list after deleting and merging grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b74f1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "all_grains, labels, mask_all, fig, ax = seg.get_grains_from_patches(ax, big_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f26a3cb",
   "metadata": {},
   "source": [
    "Plot the updated set of grains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e5539658",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.imshow(big_im)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "seg.plot_image_w_colorful_grains(big_im, all_grains, ax, cmap='Paired')\n",
    "# seg.plot_grain_axes_and_centroids(all_grains, labels, ax, linewidth=1, markersize=10)\n",
    "plt.xlim([0, np.shape(big_im)[1]])\n",
    "plt.ylim([np.shape(big_im)[0], 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845d02e",
   "metadata": {},
   "source": [
    "## Add new grains\n",
    "* click on unsegmented grain that you want to add\n",
    "* press the 'x' key to delete the last grain added\n",
    "* press the 'm' key to merge the last 2 grains added\n",
    "* right click outside the grain (but inside mask) to restrict the grain to a smaller mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fdf2a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(big_im) # this can take a while\n",
    "coords = []\n",
    "cid3 = fig.canvas.mpl_connect('button_press_event', lambda event: seg.onclick(event, ax, coords, big_im, predictor))\n",
    "cid4 = fig.canvas.mpl_connect('key_press_event', lambda event: seg.onpress(event, ax, fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d20aed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.canvas.mpl_disconnect(cid3)\n",
    "fig.canvas.mpl_disconnect(cid4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be391b84",
   "metadata": {},
   "source": [
    "After finished deleting / adding grain masks, run below cell to generate updated set of grains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "6b7a6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76/76 [00:00<00:00, 205.37it/s]\n"
     ]
    }
   ],
   "source": [
    "all_grains, labels, mask_all, fig, ax = seg.get_grains_from_patches(ax, big_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ca49d",
   "metadata": {},
   "source": [
    "### Save mask and grain labels to PNG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "2d1891e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = 'images/output/'\n",
    "# write grayscale mask to PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_mask.png', mask_all)\n",
    "# Define a colormap using matplotlib\n",
    "num_classes = len(all_grains)\n",
    "cmap = plt.get_cmap('viridis', num_classes)\n",
    "# Map each class label to a unique color using the colormap\n",
    "vis_mask = cmap(labels.astype(np.uint16))[:,:,:3] * 255\n",
    "vis_mask = vis_mask.astype(np.uint8)\n",
    "# Save the mask as a PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_labels.png', vis_mask)\n",
    "# Save the image as a PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_image.png', cv2.cvtColor(big_im, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d95b7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/output/0dpocx_mask.png\n"
     ]
    }
   ],
   "source": [
    "print(dirname + fname.split('/')[-1][:-4] + '_mask.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
