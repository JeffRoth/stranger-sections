{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1fe39d",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084eb915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops, regionprops_table\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from importlib import reload\n",
    "import segmenteverygrain as seg\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from tqdm import trange\n",
    "import urllib.request\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7c981",
   "metadata": {},
   "source": [
    "### Enhance training images with Adaptive Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22c2eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "def perform_adaptive_equalization(img_path, clip_lim=0.01):\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Adaptive Equalization\n",
    "    img_adapteq = exposure.equalize_adapthist(img, clip_limit=clip_lim)\n",
    "\n",
    "    return(img_adapteq)\n",
    "\n",
    "# image_dir = 'images/ara-train/'\n",
    "image_dir = 'images/ara-test/subset/'\n",
    "output_dir = image_dir + 'enhanced/'\n",
    "images = glob(image_dir + \"*.JPG\")\n",
    "\n",
    "for image in images:\n",
    "    output = perform_adaptive_equalization(image)\n",
    "    img_name = image.split(\"\\\\\")[1].split(\".\")[0] + '_enhanced' + '.jpg'\n",
    "    cv2.imwrite(output_dir + img_name, 255*output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ad8e0",
   "metadata": {},
   "source": [
    "### Download model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d253cc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sam_vit_h_4b8939.pth', <http.client.HTTPMessage at 0x1dc916b1450>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth', 'sam_vit_h_4b8939.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7e32c",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f96ebad-c16a-46b2-a68c-ef1a1578a961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "model = seg.Unet()\n",
    "model.compile(optimizer=Adam(), loss=seg.weighted_crossentropy, metrics=[\"accuracy\"])\n",
    "model.load_weights('./checkpoints/seg_model_20231009').expect_partial()\n",
    "\n",
    "sam = sam_model_registry[\"default\"](checkpoint=\"sam_vit_h_4b8939.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ceb64",
   "metadata": {},
   "source": [
    "### Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391b47a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda enabled\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    sam.to(device='cuda')\n",
    "    print(\"cuda enabled\")\n",
    "else:\n",
    "    sam.to(device='cpu')\n",
    "    print(\"cpu only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a57565d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bebab39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525fa7a",
   "metadata": {},
   "source": [
    "### Run segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a306bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:05<00:00,  1.22it/s]\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# reload(seg)\n",
    "\n",
    "# fname = 'images/ara-test/subset/enhanced/0ap9oe_enhanced.jpg'\n",
    "# fname = 'adapteq_0smyr1.jpg'\n",
    "\n",
    "big_im = np.array(load_img(fname))\n",
    "big_im_pred = seg.predict_big_image(big_im, model, I=256)\n",
    "\n",
    "labels, grains, coords = seg.label_grains(big_im, big_im_pred, dbs_max_dist=10.0)\n",
    "# all_grains, labels, mask_all, grain_data, fig, ax = seg.sam_segmentation(sam, big_im, big_im_pred, coords, labels, min_area=50.0)\n",
    "# _, _, mask_all, _, _, _ = seg.sam_segmentation(sam, big_im, big_im_pred, coords, labels, min_area=50.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d4581",
   "metadata": {},
   "source": [
    "### QC distribution of SAM prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647ec413",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(big_im_pred)\n",
    "plt.scatter(coords[:,0], coords[:,1], c='k');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a1dd22",
   "metadata": {},
   "source": [
    "### Delete or merge grains in segmentation result\n",
    "* click on the grain to remove and press 'x' key\n",
    "* click on two grains to merge, and press the 'm'm key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bf00b49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grain_inds = []\n",
    "cid1 = fig.canvas.mpl_connect('button_press_event', \n",
    "                              lambda event: seg.onclick2(event, all_grains, grain_inds, ax=ax))\n",
    "cid2 = fig.canvas.mpl_connect('key_press_event', \n",
    "                              lambda event: seg.onpress2(event, all_grains, grain_inds, fig=fig, ax=ax))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78b47f",
   "metadata": {},
   "source": [
    "Run below cell once finished with editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9f84fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.canvas.mpl_disconnect(cid1)\n",
    "fig.canvas.mpl_disconnect(cid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f274343",
   "metadata": {},
   "source": [
    "Update the 'all_grains' list after deleting and merging grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b74f1b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [00:01<00:00, 115.98it/s]\n"
     ]
    }
   ],
   "source": [
    "all_grains, labels, mask_all, fig, ax = seg.get_grains_from_patches(ax, big_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f26a3cb",
   "metadata": {},
   "source": [
    "Plot the updated set of grains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5539658",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "ax.imshow(big_im)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "seg.plot_image_w_colorful_grains(big_im, all_grains, ax, cmap='Paired')\n",
    "# seg.plot_grain_axes_and_centroids(all_grains, labels, ax, linewidth=1, markersize=10)\n",
    "plt.xlim([0, np.shape(big_im)[1]])\n",
    "plt.ylim([np.shape(big_im)[0], 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845d02e",
   "metadata": {},
   "source": [
    "## Add new grains\n",
    "* click on unsegmented grain that you want to add\n",
    "* press the 'x' key to delete the last grain added\n",
    "* press the 'm' key to merge the last 2 grains added\n",
    "* right click outside the grain (but inside mask) to restrict the grain to a smaller mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fdf2a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(big_im) # this can take a while\n",
    "coords = []\n",
    "cid3 = fig.canvas.mpl_connect('button_press_event', lambda event: seg.onclick(event, ax, coords, big_im, predictor))\n",
    "cid4 = fig.canvas.mpl_connect('key_press_event', lambda event: seg.onpress(event, ax, fig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d20aed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.canvas.mpl_disconnect(cid3)\n",
    "fig.canvas.mpl_disconnect(cid4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be391b84",
   "metadata": {},
   "source": [
    "After finished deleting / adding grain masks, run below cell to generate updated set of grains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6b7a6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 155/155 [00:01<00:00, 119.97it/s]\n"
     ]
    }
   ],
   "source": [
    "all_grains, labels, mask_all, fig, ax = seg.get_grains_from_patches(ax, big_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48ca49d",
   "metadata": {},
   "source": [
    "### Save mask and grain labels to PNG files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d1891e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirname = 'images/labeled/'\n",
    "# write grayscale mask to PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_mask.png', mask_all)\n",
    "# Define a colormap using matplotlib\n",
    "num_classes = len(all_grains)\n",
    "cmap = plt.get_cmap('viridis', num_classes)\n",
    "# Map each class label to a unique color using the colormap\n",
    "vis_mask = cmap(labels.astype(np.uint16))[:,:,:3] * 255\n",
    "vis_mask = vis_mask.astype(np.uint8)\n",
    "# Save the mask as a PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_labels.png', vis_mask)\n",
    "# Save the image as a PNG file\n",
    "cv2.imwrite(dirname + fname.split('/')[-1][:-4] + '_image.png', cv2.cvtColor(big_im, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d95b7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/output/0dpocx_mask.png\n"
     ]
    }
   ],
   "source": [
    "print(dirname + fname.split('/')[-1][:-4] + '_mask.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
